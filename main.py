import asyncio
import os
import time
from datetime import datetime, timedelta

from dotenv import load_dotenv

from db import ImageDB
from downloader import PixivDownloader
from utils import batch_create_images

load_dotenv()
DATABASE_URL = os.getenv("DATABASE_URL")
PROXY = os.getenv("PROXY")
TOKEN = os.getenv("PHPSESSID")


async def run_scrap():
  tag = "ã‚¢ãƒ­ãƒŠ(ãƒ–ãƒ«ãƒ¼ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–)"
  tag = "ãƒ—ãƒ©ãƒŠ(ãƒ–ãƒ«ãƒ¼ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–)"
  tag = "ã‚­ã‚µã‚­(ãƒ–ãƒ«ãƒ¼ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–)"
  tag = "ç©ºå´ãƒ’ãƒŠ"
  tag = "å°é³¥éŠãƒ›ã‚·ãƒ"
  tag = "è–åœ’ãƒŸã‚«"
  tag = "å®‡æ²¢ãƒ¬ã‚¤ã‚µ"
  tag = "ä¸‹æ±Ÿã‚³ãƒãƒ«"
  tag = "ä¼Šè½ãƒãƒªãƒ¼"
  tag = "æœˆé›ªãƒŸãƒ¤ã‚³"
  tag = "ç™¾åˆåœ’ã‚»ã‚¤ã‚¢"
  tag = "ä¸¹èŠ±ã‚¤ãƒ–ã‚­"
  tag = "ãƒ‹ãƒ¤ãƒ‹ãƒ¤æ•™æˆ"
  tag = "éœæ²¢ãƒŸãƒ¦"
  tag = "å†…æµ·ã‚¢ã‚ªãƒ"
  tag = "ã‚·ãƒ¥ãƒã‚¬ã‚­"
  tag = "ã‚¯ã‚ºãƒãƒ(ãƒ–ãƒ«ãƒ¼ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–)"
  tag = "æµ…é»„ãƒ ãƒ„ã‚­"
  tag = "é™¸å…«é­”ã‚¢ãƒ«"
  tag = "ç™½æ´²ã‚¢ã‚ºã‚µ"
  tag = "é˜¿æ…ˆè°·ãƒ’ãƒ•ãƒŸ"
  tag = "æŸšé³¥ãƒŠãƒ„"
  tag = "å¤©ç«¥ã‚¢ãƒªã‚¹"
  tag = "æ˜¥åŸã‚³ã‚³ãƒŠ"
  tag = "ä¸¹èŠ±ã‚¤ãƒ–ã‚­"
  tag = "æå±±ã‚«ã‚ºã‚µ"
  tag = "ç ‚ç‹¼ã‚·ãƒ­ã‚³"
  tag = "æ‰ç¾½ãƒ¢ãƒ¢ã‚¤"
  tag = "é£›é³¥é¦¬ãƒˆã‚­"
  tag = "é»’è¦‹ã‚»ãƒªã‚«"
  tag = "èª¿æœˆãƒªã‚ª"
  tag = "æ­£ç¾©å®Ÿç¾å§”å“¡ä¼šã®ãƒ¢ãƒ–"

  db = ImageDB()
  await db.connect()

  page = 1

  async with PixivDownloader(token=TOKEN or "", proxy=PROXY) as downloader:
    data, pages, total = await downloader.download_by_tag(
      keyword=tag,
      p=page,
    )
    if pages == 1000:
      print("ğŸš¨ çˆ¬å–å¤±è´¥ï¼Œè¶…è¿‡ 1000 é¡µé™åˆ¶")
      return

    print(f" {tag}ğŸ“¥ {pages} é¡µï¼Œå…± {total} å¼ æ’ç”»")

    max_retries = 10
    retry_delay = 20

    while page <= pages:
      print(f"ğŸ“¥ ç¬¬ {page}/{pages} é¡µ")
      retries = 0
      while retries < max_retries:
        try:
          data, _, _ = await downloader.download_by_tag(
            keyword=tag,
            p=page,
          )
          if data:
            break
        except Exception as e:
          print(f"âŒ ç¬¬ {page} é¡µè¯·æ±‚å‡ºé”™ï¼š{e}")

        retries += 1
        print(f"ğŸ” ç¬¬ {page} é¡µé‡è¯• {retries}/{max_retries} æ¬¡â€¦")
        await asyncio.sleep(retry_delay)

      if not data:
        print(f"âš ï¸ ç¬¬ {page} é¡µæ•°æ®è·å–å¤±è´¥ï¼Œè·³è¿‡")
        page += 1
        continue

      try:
        await batch_create_images(data)
      except Exception as e:
        print(f"âŒ ç¬¬ {page} é¡µå…¥åº“å¤±è´¥ï¼š{e}")

      if page % 90 == 0 and pages - page > 50:
        print("â¸ï¸ æ¯ 90 é¡µæš‚åœ 30 ç§’ï¼Œé˜²æ­¢å° IP")
        await asyncio.sleep(30)

      page += 1

  c = await db.get_image_count()
  print("\n", c)


async def query():
  db = ImageDB()
  await db.connect()

  c = await db.get_image_count()
  print("\n", c)


if __name__ == "__main__":
  asyncio.run(run_scrap())
  # asyncio.run(query())
